{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Receipts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os, lucene, threading, time\n",
    "from datetime import datetime\n",
    "\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.analysis.miscellaneous import LimitTokenCountAnalyzer\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.document import Document, Field, FieldType\n",
    "from org.apache.lucene.index import FieldInfo, IndexWriter, IndexWriterConfig, IndexOptions, DirectoryReader\n",
    "from org.apache.lucene.store import SimpleFSDirectory\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.queryparser.classic import QueryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIR = \"indexes/receipts1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw_web_joined/703_00198_2020-03-20_3_1391204_joined.json'\n",
    "df = pd.read_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f6f31898530>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucene.initVM(vmargs=['-Djava.awt.headless=true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticker(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tick = True\n",
    "\n",
    "    def run(self):\n",
    "        while self.tick:\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                                                                                                                           \n",
    "This class is loosely based on the Lucene (java implementation) demo class                                                    \n",
    "org.apache.lucene.demo.IndexFiles.  It will take a directory as an argument                                                   \n",
    "and will index all of the files in that directory and downward recursively.                                                   \n",
    "It will index on the file path, the file name and the file contents.  The                                                     \n",
    "resulting Lucene index will be placed in the current directory and called                                                     \n",
    "'index'.                                                                                                                      \n",
    "\"\"\"\n",
    "class IndexFiles(object):\n",
    "    \"\"\"Usage: python IndexFiles <doc_directory>\"\"\"\n",
    "\n",
    "    def __init__(self, df, storeDir, analyzer):\n",
    "        if not os.path.exists(storeDir):\n",
    "            os.mkdir(storeDir)\n",
    "\n",
    "        store = SimpleFSDirectory(Paths.get(storeDir))\n",
    "#         analyzer = LimitTokenCountAnalyzer(analyzer, 1048576)\n",
    "        config = IndexWriterConfig(analyzer)\n",
    "        config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n",
    "        writer = IndexWriter(store, config)\n",
    "\n",
    "        self.indexDocs(df, writer)\n",
    "        ticker = Ticker()\n",
    "        print('commit index',)\n",
    "        threading.Thread(target=ticker.run).start()\n",
    "        writer.commit()\n",
    "        writer.close()\n",
    "        ticker.tick = False\n",
    "        print('done')\n",
    "        \n",
    "    def indexDocs(self, df, writer):\n",
    "        t1 = FieldType()\n",
    "        t1.setStored(True)\n",
    "        t1.setTokenized(False)\n",
    "        t1.setIndexOptions(IndexOptions.DOCS_AND_FREQS)\n",
    "\n",
    "        t2 = FieldType()\n",
    "#         t2.setStored(False)\n",
    "        t2.setStored(True)\n",
    "        t2.setTokenized(True)\n",
    "        t2.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "        \n",
    "        for row in df.iterrows():\n",
    "            raw, web, id = (row[1]['raw'], row[1]['web'], row[1]['id'])\n",
    "            print(\"adding %s\" % web)\n",
    "            try:\n",
    "                doc = Document()\n",
    "                doc.add(Field(\"raw\", raw, t1))\n",
    "                doc.add(Field(\"web\", web, t2))\n",
    "                doc.add(Field(\"id\", id, t1))\n",
    "                writer.addDocument(doc)\n",
    "            except Exception as e:\n",
    "                print(\"Failed in indexDocs: %s\" % e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_test1():\n",
    "    print('lucene version %s' % lucene.VERSION)\n",
    "    start = datetime.now()\n",
    "    try:\n",
    "        IndexFiles(df, INDEX_DIR, StandardAnalyzer())\n",
    "        end = datetime.now()\n",
    "        print('Elapsed: %s' % (end - start))\n",
    "    except Exception as e:\n",
    "        print(\"Failed: %s\" % e)\n",
    "        raise e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucene version 8.1.1\n",
      "adding (LMTD QTY) Essentia Ionized Alkaline Water\n",
      "adding (LMTD QTY) FIJI Natural Artesian Water\n",
      "adding (LMTD QTY) Kroger® Spring Water\n",
      "adding (LMTD QTY) Robitussin Max Strength Blue Raspberry Nighttime Cough DM Liquid\n",
      "adding $000.10 CRV DEPOSIT\n",
      "adding $000.10 CRV DEPOSIT\n",
      "adding ABOUND™ Natural Clumping Cat Litter\n",
      "adding Artichoke\n",
      "adding Atkins Endulge Chocolate Coconut Treat Bar\n",
      "adding Avocado - Small\n",
      "adding Beef Choice For Stir Fry\n",
      "adding Beyond Meat Hot Italian Plant-Based Sausage\n",
      "adding Beyond Meat The Beyond Burger Plant-Based Burger Patties\n",
      "adding Boar's Head Monterey Jack with Jalapeno Pre-Sliced Cheese\n",
      "adding Broccoli\n",
      "adding Cauliflower\n",
      "adding Celery - Small\n",
      "adding Cholula Original Hot Sauce\n",
      "adding Cucumber - English\n",
      "adding Del Cabo Cucumber Og 16 Oz\n",
      "adding Earthwise Palm Trees Reusable Shopping Bag\n",
      "adding Fancy Feast Classic Pate Cod Sole & Shrimp Feast Wet Cat Food\n",
      "adding Fancy Feast Classic Pate Tender Liver & Chicken Feast Wet Cat Food\n",
      "adding Fancy Feast Flaked Fish & Shrimp Feast Wet Cat Food\n",
      "adding Frigo Cheese Heads Low Moisture Part Skim Original Mozzarella String Cheese\n",
      "adding Galbani String Cheese\n",
      "adding Hefty Storage Slider Bags\n",
      "adding Kroger® Honey Citrus & Shea Butter Hand Soap Bottle\n",
      "adding Kroger® Beef Shaved Steak\n",
      "adding Kroger® Pear & Coconut Hand Soap\n",
      "adding Kroger® Premium Coconut Milk\n",
      "adding Kroger® Romaine Leaf Single Cut Leaf\n",
      "adding Kroger® Romaine Lettuce Hearts\n",
      "adding Kroger® Whole Baby Bella Mushrooms\n",
      "adding Les Petites Havarati Cheese Wedge\n",
      "adding Les Petites Kosher Colby Jack Cheese\n",
      "adding MEAT FS\n",
      "adding MEAT FS\n",
      "adding Mezzetta Pitted Greek Kalamata Olives\n",
      "adding Mountain High Plain Original Whole Milk Yoghurt\n",
      "adding NO CHICKEN BROTH TETRA\n",
      "adding Nut Pods Hazelnut Unsweetened Dairy-Free Creamer\n",
      "adding Onions - Green\n",
      "adding Onions - Red - Jumbo\n",
      "adding Onions - Yellow\n",
      "adding Organic - Asparagus\n",
      "adding Organic - Cabbage - Green\n",
      "adding Organic - Cabbage - Red\n",
      "adding Organic - Parsley - Curly\n",
      "adding Organic - Peppers - Green Bell\n",
      "adding Organic - Radishes\n",
      "adding Organic - Squash - Yellow\n",
      "adding Organic - Tomatoes - On the Vine\n",
      "adding Organic Italian Parsley\n",
      "adding Oscar Mayer Naturally Hardwood Smoked Bacon Mega Pack\n",
      "adding Patak Mild Curry Spice Paste\n",
      "adding Pero Organic Green Beans\n",
      "adding Private Selection™ Campari Tomatoes\n",
      "adding Private Selection™ Grab & Go Maple Turkey Breast\n",
      "adding Private Selection™ Grab & Go Muenster Cheese\n",
      "adding Purina Fancy Feast Classic Pate Chicken Feast Wet Cat Food Can\n",
      "adding Purina Fancy Feast Classic Pate Savory Salmon Feast Wet Cat Food Can\n",
      "adding Purina Fancy Feast Classic Pate Tender Beef Feast Wet Cat Food Can\n",
      "adding Purina Fancy Feast Minced Turkey Feast in Sauce Wet Cat Food Can\n",
      "adding Purina Fancy Feast Sliced Chicken Hearts & Liver Feast in Gravy Wet Cat Food Can\n",
      "adding Simple Truth Organic™ Baby Carrots\n",
      "adding Simple Truth Organic™ Baby Spring Mix\n",
      "adding Simple Truth Organic™ Basil\n",
      "adding Simple Truth Organic™ Coconut Milk\n",
      "adding Simple Truth Organic™ Fat Free Beef Stock\n",
      "adding Simple Truth Organic™ Fat Free Free Range Chicken Broth\n",
      "adding Simple Truth Organic™ Whole Carrots\n",
      "adding Simple Truth™ Natural Angus Beef Chuck Roast\n",
      "adding Simple Truth™ Pecan Halves\n",
      "adding Simple Truth™ Sea Salt Roasted Cashews\n",
      "adding Smart Chicken Organic Ground Chicken 95% Lean\n",
      "adding Softsoap Fresh Breeze Liquid Hand Soap\n",
      "adding Softsoap Kitchen Fresh Hands Citrus Extracts Antibacterial Hand Soap\n",
      "adding Squash - Spaghetti\n",
      "adding Taylor Farms Avocado Ranch Chopped Salad Kit\n",
      "adding Taylor Farms Roasted Garlic Chopped Salad Kit\n",
      "adding Veroni Italy Salame Calabrese\n",
      "adding Veroni Italy Salame Milano\n",
      "adding Ziploc Quart Freezer Bags\n",
      "commit index\n",
      ".done\n",
      "Elapsed: 0:00:00.052894\n"
     ]
    }
   ],
   "source": [
    "index_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_loop():\n",
    "    searcher = IndexSearcher(DirectoryReader.open(SimpleFSDirectory(Paths.get(INDEX_DIR))))\n",
    "    analyzer = StandardAnalyzer()\n",
    "    print(\"Hit enter with no input to quit.\")\n",
    "    while True:\n",
    "        command = input(\"Query:\")\n",
    "        if command == '':\n",
    "            return\n",
    "        print(\"Searching for: %s\" % command)\n",
    "        query = QueryParser(\"web\", analyzer).parse(command)\n",
    "        scoreDocs = searcher.search(query, 50).scoreDocs\n",
    "        print(\"%s total matching documents.\" % len(scoreDocs))\n",
    "\n",
    "        for scoreDoc in scoreDocs:\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            print(doc.get(\"id\"), ':', doc.get(\"web\"), \"|\", doc.get(\"raw\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit enter with no input to quit.\n",
      "Query:ABOUND CAT LITTER\n",
      "Searching for: ABOUND CAT LITTER\n",
      "9 total matching documents.\n",
      "1111080010 : ABOUND™ Natural Clumping Cat Litter | ABOUND CAT LITTER\n",
      "5000042874 : Fancy Feast Flaked Fish & Shrimp Feast Wet Cat Food | FFST CAT FOOD\n",
      "5000042894 : Fancy Feast Classic Pate Cod Sole & Shrimp Feast Wet Cat Food | FFST CAT FOOD\n",
      "5000042904 : Fancy Feast Classic Pate Tender Liver & Chicken Feast Wet Cat Food | FFST CAT FOOD\n",
      "5000042994 : Purina Fancy Feast Classic Pate Chicken Feast Wet Cat Food Can | FFST CAT FOOD\n",
      "5000042944 : Purina Fancy Feast Classic Pate Savory Salmon Feast Wet Cat Food Can | FFST CAT FOOD\n",
      "5000042954 : Purina Fancy Feast Classic Pate Tender Beef Feast Wet Cat Food Can | FFST CAT FOOD\n",
      "5000043494 : Purina Fancy Feast Minced Turkey Feast in Sauce Wet Cat Food Can | FFST CAT FOOD\n",
      "5000043464 : Purina Fancy Feast Sliced Chicken Hearts & Liver Feast in Gravy Wet Cat Food Can | FFST CAT FOOD\n",
      "Query:ARTICHOKES\n",
      "Searching for: ARTICHOKES\n",
      "0 total matching documents.\n",
      "Query:ARTICHOKE\n",
      "Searching for: ARTICHOKE\n",
      "1 total matching documents.\n",
      "4762 : Artichoke | ARTICHOKES\n",
      "Query:ATKINS BARS\n",
      "Searching for: ATKINS BARS\n",
      "1 total matching documents.\n",
      "63748007506 : Atkins Endulge Chocolate Coconut Treat Bar | ATKINS BARS\n",
      "Query:AVOCADO HASS\n",
      "Searching for: AVOCADO HASS\n",
      "2 total matching documents.\n",
      "4046 : Avocado - Small | AVOCADO HASS\n",
      "3022304150 : Taylor Farms Avocado Ranch Chopped Salad Kit | TYFR SALAD KIT\n",
      "Query:\n"
     ]
    }
   ],
   "source": [
    "search_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO EVALUATE\n",
    "```\n",
    "build a table of raw -> [web]\n",
    "where [web] is all the possible values of matches for raw\n",
    "example: 'FFST CAT FOOD' -> ['Fancy Feast Flaked Fish Cat Food', 'Purina Fancy Feast Chicken Cat Food']\n",
    "\n",
    "search on query (e.g. FFST CAT FOOD) if top result is any of the ones associated with query, it counts as a hit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea\n",
    "```\n",
    "when building a query evaluate against dictionary of seen web terms\n",
    "unseen tokens get wildcard treatment\n",
    "wildcard treatment means insert * between each letter\n",
    "e.g., FFST CAT FOOD -> F*F*S*T CAT FOOD\n",
    "since cat and food exist in dictionary\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           ESNT WATER\n",
       "1           FIJI WATER\n",
       "2            KRO WATER\n",
       "3     ROBITUSSIN COUGH\n",
       "4         CA REDEM VAL\n",
       "5         CA REDEM VAL\n",
       "6    ABOUND CAT LITTER\n",
       "7           ARTICHOKES\n",
       "8          ATKINS BARS\n",
       "9         AVOCADO HASS\n",
       "Name: raw, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['raw'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_word(word):\n",
    "    import re\n",
    "    word = word.lower()\n",
    "    p = re.compile('[^a-z-]')\n",
    "    word = p.sub('', word)\n",
    "    return word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(df):\n",
    "    \"\"\"\n",
    "    Extract all tokens from 'web' column of 'df'.\n",
    "    Return set of tokens\n",
    "    \"\"\"\n",
    "    result = set()\n",
    "    for sent in df.web.unique():\n",
    "        for word in sent.split():\n",
    "            nword = normalize_word(word)\n",
    "            if nword:\n",
    "                result.add(nword)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = make_dictionary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_to_web(df):\n",
    "    from collections import defaultdict\n",
    "    raw_to_web = defaultdict(list)\n",
    "    for row in df.iterrows():\n",
    "        raw, web = (row[1]['raw'], row[1]['web'])\n",
    "        raw_to_web[raw].append(web)\n",
    "    return raw_to_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_TO_WEB = make_raw_to_web(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "### Interface\n",
    "```\n",
    "def is_hit(raw, config): -> bool\n",
    "\n",
    "config:\n",
    "  Index\n",
    "  Searcher\n",
    "  QueryMaker\n",
    "```\n",
    "\n",
    "Algorithm:\n",
    "We lookup the webs for the webs for the raw to generate the hit candidates\n",
    "we process raw into a query using QueryMaker\n",
    "We run the query using Searcher\n",
    "Index may not be necessary\n",
    "If the top result is in webs, we return true, otherwise false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryMaker:\n",
    "    def make_query(raw):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleQueryMaker(QueryMaker):\n",
    "    def make_query(self, raw):\n",
    "        return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm = SimpleQueryMaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FFST CAT'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm.make_query('FFST CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Searcher:\n",
    "    def search(self, query):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSearcher(Searcher):\n",
    "    def __init__(self):\n",
    "        self.searcher = IndexSearcher(DirectoryReader.open(SimpleFSDirectory(Paths.get(INDEX_DIR))))\n",
    "        self.analyzer = StandardAnalyzer()\n",
    "\n",
    "    def search(self, qstring):\n",
    "        query = QueryParser(\"web\", self.analyzer).parse(qstring)\n",
    "        scoreDocs = self.searcher.search(query, 50).scoreDocs\n",
    "        return [self.searcher.doc(score_doc.doc) for score_doc in scoreDocs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SimpleSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ss.search('FFST CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0=docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document: Document<stored,indexed,tokenized,indexOptions=DOCS_AND_FREQS<raw:ABOUND CAT LITTER> stored,indexed,tokenized<web:ABOUND™ Natural Clumping Cat Litter> stored<id:1111080010>>>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1111080010'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABOUND™ Natural Clumping Cat Litter'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0.get('web')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, query_maker, searcher):\n",
    "        self.query_maker = query_maker\n",
    "        self.searcher = searcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_config = Config(qm, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SimpleSearcher at 0x7f6f0c465b10>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_config.searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hit(raw, config):\n",
    "    query = config.query_maker.make_query(raw)\n",
    "    docs = config.searcher.search(query)\n",
    "    if not docs:\n",
    "        return False\n",
    "    top_doc = docs[0]\n",
    "    top_web = top_doc.get('web')\n",
    "    if raw not in RAW_TO_WEB:\n",
    "        return False\n",
    "    web_candidates = RAW_TO_WEB[raw]\n",
    "    if top_web not in web_candidates:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_hit('FFST CAT FOOD', simple_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_hit('AVOCADO', simple_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(queries, config):\n",
    "    num_queries = len(queries)\n",
    "    total_hits = 0\n",
    "    missed_queries = []\n",
    "    for query in queries:\n",
    "        if is_hit(query, config):\n",
    "            total_hits += 1\n",
    "        else:\n",
    "            missed_queries.append(query)\n",
    "    precision = total_hits/num_queries\n",
    "    return precision, missed_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['AVOCADO', 'FFST CAT FOOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, ['AVOCADO'])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(queries, simple_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df.raw.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_score, simple_misses = evaluate(queries, simple_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KRO WATER',\n",
       " 'CA REDEM VAL',\n",
       " 'ARTICHOKES',\n",
       " 'BYND SSG HT ITLN',\n",
       " 'BRHD CHEESE',\n",
       " 'CUCUMBERS',\n",
       " 'FRGO STR CHS',\n",
       " 'GLBNI STR CHS',\n",
       " 'KRO SOAP',\n",
       " 'KRO CCNT MK',\n",
       " 'MSHRM BYBL WHL',\n",
       " 'LES PET CHEESE BAR',\n",
       " 'BROWN ONIONS',\n",
       " 'ASP ORG',\n",
       " 'PPRS BL GRN ORGN',\n",
       " 'RADISH ORG',\n",
       " 'SQSH YLW ORG',\n",
       " 'TOMATO ORGNC',\n",
       " 'PRSL MPL TKY GNG',\n",
       " 'PRSL MUENSTR',\n",
       " 'STO CRT BABY ORGNC',\n",
       " 'STO CCNT MILK',\n",
       " 'STO BROTH',\n",
       " 'STO CARROTS ORGNC',\n",
       " 'STN CHCK RST',\n",
       " 'SFTSOAP KTCHN FRSH']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'abc'\n",
    "s2 = ''\n",
    "for c in s:\n",
    "    s2 += c + '*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a*b*c*'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wildcard_query(q):\n",
    "    words = q.split()\n",
    "    nwords = [normalize_word(word) for word in words]\n",
    "    tokens = []\n",
    "    for nword in nwords:\n",
    "        if nword not in WORDS:\n",
    "            wild_word = ''\n",
    "            for c in nword:\n",
    "                wild_word += c + '*'\n",
    "            tokens.append(wild_word)\n",
    "        else:\n",
    "            tokens.append(nword)\n",
    "    return ' '.join(tokens)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f*f*s*t* cat food'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_wildcard_query('FFST CAT FOOD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildQueryMaker(QueryMaker):\n",
    "    def make_query(self, raw):\n",
    "        return make_wildcard_query(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqm = WildQueryMaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_config = Config(wqm, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_score, wild_misses = evaluate(queries, wild_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405797101449275"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wild_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KRO WATER',\n",
       " 'CA REDEM VAL',\n",
       " 'ARTICHOKES',\n",
       " 'BYND SSG HT ITLN',\n",
       " 'BRHD CHEESE',\n",
       " 'CUCUMBERS',\n",
       " 'FRGO STR CHS',\n",
       " 'GLBNI STR CHS',\n",
       " 'KRO SOAP',\n",
       " 'KRO CCNT MK',\n",
       " 'MSHRM BYBL WHL',\n",
       " 'LES PET CHEESE BAR',\n",
       " 'BROWN ONIONS',\n",
       " 'ASP ORG',\n",
       " 'PPRS BL GRN ORGN',\n",
       " 'RADISH ORG',\n",
       " 'SQSH YLW ORG',\n",
       " 'TOMATO ORGNC',\n",
       " 'PRSL MPL TKY GNG',\n",
       " 'PRSL MUENSTR',\n",
       " 'STO CRT BABY ORGNC',\n",
       " 'STO CCNT MILK',\n",
       " 'STO BROTH',\n",
       " 'STO CARROTS ORGNC',\n",
       " 'STN CHCK RST',\n",
       " 'SFTSOAP KTCHN FRSH']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA REDEM VAL',\n",
       " 'ARTICHOKES',\n",
       " 'BRHD CHEESE',\n",
       " 'CUCUMBERS',\n",
       " 'KRO SOAP',\n",
       " 'LES PET CHEESE BAR',\n",
       " 'BROWN ONIONS',\n",
       " 'PRSL MUENSTR',\n",
       " 'STO CCNT MILK',\n",
       " 'STO BROTH',\n",
       " 'STO CARROTS ORGNC']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wild_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ASP ORG',\n",
       " 'BYND SSG HT ITLN',\n",
       " 'FRGO STR CHS',\n",
       " 'GLBNI STR CHS',\n",
       " 'KRO CCNT MK',\n",
       " 'KRO WATER',\n",
       " 'MSHRM BYBL WHL',\n",
       " 'PPRS BL GRN ORGN',\n",
       " 'PRSL MPL TKY GNG',\n",
       " 'RADISH ORG',\n",
       " 'SFTSOAP KTCHN FRSH',\n",
       " 'SQSH YLW ORG',\n",
       " 'STN CHCK RST',\n",
       " 'STO CRT BABY ORGNC',\n",
       " 'TOMATO ORGNC'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(simple_misses) - set(wild_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
